apiVersion: v1
kind: Service
metadata:
  name: pan-mgmt-svc-1
  namespace: kube-system
  labels:
    app: pan-mgmt-svc-1
spec:
  ports:
  - protocol: UDP
    port: 4500
    name: ipsec
  selector:
    appname: pan-mgmt-sts-1
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pan-mgmt-sts-1
  namespace: kube-system
spec:
  selector:
    matchLabels:
      appname: pan-mgmt-sts-1
  serviceName: pan-mgmt-svc-1
  # Max 1 replicas supported.
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        app: pan-mgmt
        appname: pan-mgmt-sts-1
      annotations:
          paloaltonetworks.com/app: pan-mgmt
    spec:
    {{- if .Values.nodeSelector }}
    nodeSelector: {{ toYaml .Values.nodeSelector | nindent 8 }}
    {{- end }}
      serviceAccountName: pan-mgmt-sa
      priorityClassName: system-node-critical
      {{- if .Values.mp.node_selector_mp1_Key }}
      nodeSelector:
      #  firewall: pan-ngfw-dep-1
        {{ .Values.mp.node_selector_mp1_Key  }} :  {{ .Values.mp.node_selector_mp1_value  }}
      {{- end }}      
      #terminationGracePeriodSeconds: 60 //for graceful exit of prestop hook
      # Turn on podAntiAffinity to schedule HA pair MGMT pods on separate nodes
      # Turn off podAntiAffinity, if you want to schedule on same node
      affinity:
       podAntiAffinity:
         requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
                 - key: "appname"
                   operator: In
                   values:
                   - pan-mgmt-sts-0
             topologyKey: "kubernetes.io/hostname"
      initContainers:
        - name: pan-mgmt-init
          image: "{{ .Values.mp.initImage }}:{{ .Values.mp.initVersion }}"
          command: ["/usr/bin/pan_start.sh"]
          imagePullPolicy: Always
          securityContext:
            privileged: true
            capabilities:
              add: ["ALL"]
          volumeMounts:
          - name: panconfig
            mountPath: /opt/pancfg/
          - name: varlogpan
            mountPath: /var/log/pan/
          envFrom:
          - configMapRef:
              name: pan-mgmt-config-1
          env:
          - name: MY_POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: MY_POD_UID
            valueFrom:
              fieldRef:
                fieldPath: metadata.uid
          - name: PAN_DP_NAME
            # Needs to match the prefix in secret volume
            # sw-secret in pan-cn-ngfw-1.yaml and hard-coded in ipsec.conf
            value: pan-fw-1
      containers:
        - name: pan-mgmt
          image: "{{ .Values.mp.image }}:{{ .Values.mp.version }}"
          terminationMessagePolicy: FallbackToLogsOnError
          command: ["/sbin/pan_start"]
          lifecycle:
            preStop:
              exec:
                command: ["/sbin/pan_shutdown"]
          readinessProbe:
            exec:
              command: ["/sbin/pan_ready_check"]
            initialDelaySeconds: 30
            periodSeconds: 2
            failureThreshold: 2
            successThreshold: 2
          livenessProbe:
            exec:
              command: ["/sbin/pan_alive_check"]
            initialDelaySeconds: 600 #covers image download and panos start
            periodSeconds: 5
            failureThreshold: 2
          imagePullPolicy: Always
          securityContext:
            privileged: true
            capabilities:
              add: ["ALL"]
          resources:
            requests:
              # configurable based on desired logging, capacities
              cpu: "{{ .Values.mp.cpuLimit }}"
              memory: "{{ .Values.mp.memoryLimit }}"
            limits:
              cpu: "{{ .Values.mp.cpuLimit }}"
              memory: "{{ .Values.mp.memoryLimit }}"
          volumeMounts:
          - name: panlogs
            mountPath: /opt/panlogs/
          - name: varlogpan
            mountPath: /var/log/pan/
          - name: varcores
            mountPath: /var/cores/
          - name: panconfig
            mountPath: /opt/pancfg/
          - name: panplugins
            mountPath: /opt/plugins/installed/
          - name: panplugincfg
            mountPath: /opt/pancfg/mgmt/plugins/
          - name: panplugincfg
            mountPath: /opt/plugins/opt/pancfg/mgmt/plugins/
          - mountPath: /dev/shm
            name: dshm
          envFrom:
          - configMapRef:
              name: pan-mgmt-config-1
          env:
          - name: MY_POD_UID
            valueFrom:
              fieldRef:
                fieldPath: metadata.uid
          - name: MY_POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: MY_POD_SERVICE_ACCOUNT
            valueFrom:
              fieldRef:
                fieldPath: spec.serviceAccountName
          - name: MY_NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: PAN_DP_NAME
            # Needs to match the prefix in secret volume
            # sw-secret in pan-cn-ngfw.yaml and hard-coded in ipsec.conf
            value: pan-fw-1
      {{- if .Values.imagePullSecrets }}
      imagePullSecrets:
      - name: "{{ .Values.imagePullSecrets }}" 
      {{- end }}     
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
  volumeClaimTemplates:
  - metadata:
      name: panlogs
    spec:
      #storageClassName: pan-cn-storage-class //For better disk iops performance for logging
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi # change this to 200Gi while using storageClassName for better disk iops
      {{- if and (eq .Values.cluster.volumes "static") (eq .Values.cluster.deployTo "native") }}
       # Note: Use of dynamically provisioned PVs is strongly recommend.	
      # Disable storageClassName to use dynamically provisioned PVs.	
      #	
      # Enable this to use manual PVs (for single node clusters only), after	
      # deploying manual PVs with matching storage capacities (can use 	
      # provided pan-cn-pv-manual.yaml as is).	
      #storageClassName: manual	
      #	
      # Enable this to use Local PVs, after deploying pan-local-storage 	
      # storageclass and PVs (refer provided pan-cn-pv-local.yaml) and 	
      # after creating the mount point on the host nodes for local PVs .	
      storageClassName: pan-local-storage	
      selector:	
        matchLabels:	
            pv: panlogs1
      {{- end }}
  - metadata:
      name: varlogpan
    spec:
      #storageClassName: pan-cn-storage-class //For better disk iops performance for dp logs
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi # change this to 200Gi while using storageClassName for better disk iops
      {{- if and (eq .Values.cluster.volumes "static") (eq .Values.cluster.deployTo "native") }}
      # Note: Use of dynamically provisioned PVs is strongly recommend.	
      # Disable storageClassName to use dynamically provisioned PVs.	
      #	
      # Enable this to use manual PVs (for single node clusters only), after	
      # deploying manual PVs with matching storage capacities (can use 	
      # provided pan-cn-pv-manual.yaml as is).	
      #storageClassName: manual	
      #	
      # Enable this to use Local PVs, after deploying pan-local-storage 	
      # storageclass and PVs (refer provided pan-cn-pv-local.yaml) and 	
      # after creating the mount point on the host nodes for local PVs .	
      storageClassName: pan-local-storage	
      selector:	
        matchLabels:	
            pv: panvarlog1
      {{- end }}
  - metadata:
      name: varcores
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 2Gi
      {{- if and (eq .Values.cluster.volumes "static") (eq .Values.cluster.deployTo "native") }}
       # Note: Use of dynamically provisioned PVs is strongly recommend.	
      # Disable storageClassName to use dynamically provisioned PVs.	
      #	
      # Enable this to use manual PVs (for single node clusters only), after	
      # deploying manual PVs with matching storage capacities (can use 	
      # provided pan-cn-pv-manual.yaml as is).	
      #storageClassName: manual	
      #	
      # Enable this to use Local PVs, after deploying pan-local-storage 	
      # storageclass and PVs (refer provided pan-cn-pv-local.yaml) and 	
      # after creating the mount point on the host nodes for local PVs .	
      storageClassName: pan-local-storage	
      selector:	
        matchLabels:	
            pv: panvarcores1
      {{- end }}

  - metadata:
      name: panplugincfg
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
      {{- if and (eq .Values.cluster.volumes "static") (eq .Values.cluster.deployTo "native") }}
      # Note: Use of dynamically provisioned PVs is strongly recommend.	
      # Disable storageClassName to use dynamically provisioned PVs.	
      #	
      # Enable this to use manual PVs (for single node clusters only), after	
      # deploying manual PVs with matching storage capacities (can use 	
      # provided pan-cn-pv-manual.yaml as is).	
      #storageClassName: manual	
      #	
      # Enable this to use Local PVs, after deploying pan-local-storage 	
      # storageclass and PVs (refer provided pan-cn-pv-local.yaml) and 	
      # after creating the mount point on the host nodes for local PVs .	
      storageClassName: pan-local-storage	
      selector:	
        matchLabels:	
            pv: panplugincfg1
      {{- end }}
  - metadata:
      name: panconfig
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 8Gi
      {{- if and (eq .Values.cluster.volumes "static") (eq .Values.cluster.deployTo "native") }}
        # Note: Use of dynamically provisioned PVs is strongly recommend.	
      # Disable storageClassName to use dynamically provisioned PVs.	
      #	
      # Enable this to use manual PVs (for single node clusters only), after	
      # deploying manual PVs with matching storage capacities (can use 	
      # provided pan-cn-pv-manual.yaml as is).	
      #storageClassName: manual	
      #	
      # Enable this to use Local PVs, after deploying pan-local-storage 	
      # storageclass and PVs (refer provided pan-cn-pv-local.yaml) and 	
      # after creating the mount point on the host nodes for local PVs .	
      storageClassName: pan-local-storage	
      selector:	
        matchLabels:	
            pv: panconfig1
      {{- end }}
  - metadata:
      name: panplugins
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Mi
      {{- if and (eq .Values.cluster.volumes "static") (eq .Values.cluster.deployTo "native") }}
        # Note: Use of dynamically provisioned PVs is strongly recommend.	
      # Disable storageClassName to use dynamically provisioned PVs.	
      #	
      # Enable this to use manual PVs (for single node clusters only), after	
      # deploying manual PVs with matching storage capacities (can use 	
      # provided pan-cn-pv-manual.yaml as is).	
      #storageClassName: manual	
      #	
      # Enable this to use Local PVs, after deploying pan-local-storage 	
      # storageclass and PVs (refer provided pan-cn-pv-local.yaml) and 	
      # after creating the mount point on the host nodes for local PVs .	
      storageClassName: pan-local-storage	
      selector:	
        matchLabels:	
            pv: panplugins1
      {{- end }}